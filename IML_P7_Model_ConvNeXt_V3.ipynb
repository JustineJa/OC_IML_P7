{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b1cd2d-1bca-45f6-a8d0-c68254583def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, Flatten, Dense, GlobalAveragePooling2D, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import streamlit as st\n",
    "from tensorflow.keras.applications import ConvNeXtTiny, ResNet50 \n",
    "from tensorflow.keras.applications.convnext import preprocess_input, decode_predictions\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "\n",
    "# Afficher la bannière\n",
    "banniere_path = 'C:/Users/Lenovo/Documents/OC_IML_P7/presentation/Img/banniere.png'\n",
    "image_ban = Image.open(banniere_path)\n",
    "st.image(image_ban, caption='Bienvenue', use_column_width=True)\n",
    "\n",
    "# Interface Streamlit\n",
    "st.title(\"Classification d'images avec ConvNeXt\")\n",
    "st.header(\"Contexte\")\n",
    "st.write(\"Il s'agit ici de blablabla\")\n",
    "\n",
    "st.header(\"Les ressources :\")\n",
    "st.write(\"Pour nos travaux nous nous basons sur le dataset fourni par l'université de Standford.\")\n",
    "st.write(\"Vous trouverez ci dessous la répartition des images par race dans ce dataset :\")\n",
    "df_races = pd.read_csv('races.csv')\n",
    "# Créer un graphique interactif avec Plotly\n",
    "fig_races = px.bar(df_races, x=\"index\", y=\"num_pictures\", title=\"Répartition des photos par race\")\n",
    "# Afficher le graphique dans Streamlit\n",
    "st.plotly_chart(fig_races)\n",
    "\n",
    "st.header(\"Les résultats :\")\n",
    "st.write(\"Dans le cadre de notre étude nous avons souhaité tester la performance de l'algorithme ConvNeXt par rapport à ResNet.\")\n",
    "st.write(\"Nous avons réalisé nos tests pour différentes cardinalités (entre 5 et 30) de classes :\")\n",
    "df_results = pd.read_csv('results_vf.csv')\n",
    "# Créer un graphique interactif avec Plotly\n",
    "fig_results = px.line(df_results, x=\"Nb_races\", y=\"Accuracy\",color = \"Model\", title=\"Accuracy par algorithme\")\n",
    "# Afficher le graphique dans Streamlit\n",
    "st.plotly_chart(fig_results)\n",
    "\n",
    "# Créer un graphique interactif avec Plotly\n",
    "fig_time = px.line(df_results, x=\"Nb_races\", y=\"Temps\",color = \"Model\", title=\"Temps par algorithme\")\n",
    "# Afficher le graphique dans Streamlit\n",
    "st.plotly_chart(fig_time)\n",
    "\n",
    "st.header(\"Testons notre algorithme !\")\n",
    "st.write(\"Téléchargez une image à classifier\")\n",
    "\n",
    "# Télécharger une image via Streamlit\n",
    "uploaded_file = st.file_uploader(\"Choisissez une image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "list_races = ['Lévrier Afghan', 'Bouledogue français', 'Bichon maltais', 'Loulou de Poméranie', 'Deerhound']\n",
    "\n",
    "#Définir la couche LayerScale\n",
    "# https://github.com/andreped/keras/blob/810fd3c203dbae8bb1f888ebc91cdd31ff30cf34/keras/applications/convnext.py#L221\n",
    "class LayerScale(layers.Layer):\n",
    "    \"\"\"Layer scale module.\n",
    "\n",
    "    References:\n",
    "      - https://arxiv.org/abs/2103.17239\n",
    "\n",
    "    Args:\n",
    "      init_values (float): Initial value for layer scale. Should be within\n",
    "        [0, 1].\n",
    "      projection_dim (int): Projection dimensionality.\n",
    "\n",
    "    Returns:\n",
    "      Tensor multiplied to the scale.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_values, projection_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.init_values = init_values\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = tf.Variable(\n",
    "            self.init_values * tf.ones((self.projection_dim,))\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.gamma\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"init_values\": self.init_values,\n",
    "                \"projection_dim\": self.projection_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "class StochasticDepth(layers.Layer):\n",
    "    \"\"\"Stochastic Depth module.\n",
    "\n",
    "    It performs batch-wise dropping rather than sample-wise. In libraries like\n",
    "    `timm`, it's similar to `DropPath` layers that drops residual paths\n",
    "    sample-wise.\n",
    "\n",
    "    References:\n",
    "      - https://github.com/rwightman/pytorch-image-models\n",
    "\n",
    "    Args:\n",
    "      drop_path_rate (float): Probability of dropping paths. Should be within\n",
    "        [0, 1].\n",
    "\n",
    "    Returns:\n",
    "      Tensor either with the residual path dropped or kept.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, drop_path_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_path_rate = drop_path_rate\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_path_rate\n",
    "            shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"drop_path_rate\": self.drop_path_rate})\n",
    "        return config\n",
    "\n",
    "# Utiliser custom_object_scope pour enregistrer LayerScale\n",
    "@st.cache_resource\n",
    "#def load_model(model_path):\n",
    "#    with custom_object_scope({'LayerScale': LayerScale, \"StochasticDepth\": StochasticDepth}):\n",
    "#        model = keras.models.load_model(model_path)\n",
    "#    return model\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = keras.models.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Fonction de prédiction\n",
    "def predict(model, img):\n",
    "    # Redimensionner l'image à la taille attendue (224, 224 pour ConvNextTiny)\n",
    "    img = img.resize((224, 224))\n",
    "\n",
    "    # Convertir l'image en tableau numpy\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Ajouter une dimension supplémentaire pour correspondre à l'entrée du modèle\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Prétraiter l'image pour le modèle ConvNextTiny\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    # Faire la prédiction\n",
    "    prediction = model.predict(img_array)\n",
    "    # Convert predictions to class labels\n",
    "    predicted_class = int(np.argmax(prediction, axis=-1))\n",
    "    \n",
    "    # Invert the predicted class indices to actual labels\n",
    "    labeled_prediction = list_races[predicted_class]\n",
    "    \n",
    "    return labeled_prediction\n",
    "\n",
    "# Charger le modèle\n",
    "model = load_model('C:/Users/Lenovo/Documents/OC_IML_P7/ConvNeXt_5.h5')\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Afficher l'image téléchargée\n",
    "    image = Image.open(uploaded_file)\n",
    "    st.image(image, caption='Image téléchargée', use_column_width=True)\n",
    "\n",
    "    # Prédire la classe de l'image\n",
    "    st.write(\"Classification en cours...\")\n",
    "    labeled_prediction = predict(model, image)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    st.write(\"Voici le résultat de la classification :\")\n",
    "    st.write(f\"La race est: {labeled_prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvP7",
   "language": "python",
   "name": "venvp7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
